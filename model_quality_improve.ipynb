{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gfSowsy_LoKZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGb9lZPLLjJC"
      },
      "source": [
        "# Practice Notebook: New Models: Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfSowsy_LoKZ"
      },
      "source": [
        "## Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1enEvozLkmw"
      },
      "source": [
        "Train a random forest model. The test set accuracy should be at least 0.88.\n",
        "\n",
        "**Hint**\n",
        "\n",
        "Try n_estimators values from 1 to 10. Pick the option with the best quality for the validation set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_EASYGtLesK"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import our data and preview the data\n",
        "diabetes_df = pd.read_csv('diabetes2.csv')\n",
        "diabetes_df.head()\n",
        "diabetes_df.sample(n=10)\n",
        "diabetes_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNXKFx9tRTK0",
        "outputId": "2e5e9a14-4ede-483a-ebce-e118e48d8183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas._libs.hashtable import duplicated\n",
        "diabetes_df.isnull().sum() #no missing value\n",
        "diabetes_df.duplicated().any() #no duplicated observation\n",
        "diabetes_df.dtypes #all columns are numeric data type\n",
        "diabetes_df.nunique() #check uniques values per columns. column 'Outcome' is classification label\n",
        "diabetes_df.columns #columns start with capital\n"
      ],
      "metadata": {
        "id": "_ojcLcHpxMOM",
        "outputId": "0033e859-907c-4172-bd95-462bc0a49eee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['pregnancies', 'glucose', 'bloodpressure', 'skinthickness', 'insulin',\n",
              "       'bmi', 'diabetespedigreefunction', 'age', 'outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#standardise the columns name\n",
        "diabetes_df.columns = diabetes_df.columns.str.lower().str.strip()\n",
        "diabetes_df.head()\n"
      ],
      "metadata": {
        "id": "6-dHQ90nzoSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data modeling\n",
        "#since there is no separate test dataset create train and validation dataset\n",
        "#use train and test split function. \n",
        "#when using the valid_df no model achieved accuracy of >=0.85\n",
        "train_df, valid_df = train_test_split(diabetes_df, test_size=1, random_state=1234)\n",
        "print(train_df.shape)\n",
        "print(valid_df.shape)"
      ],
      "metadata": {
        "id": "ka3rTc87z1wB",
        "outputId": "9ab24361-b406-418f-e71a-fdd65057b1f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(767, 9)\n",
            "(1, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create features and target for both train and test\n",
        "features_train = train_df.drop(columns=['outcome'])\n",
        "target_train = train_df['outcome']\n",
        "features_valid = valid_df.drop(columns=['outcome'])\n",
        "target_valid = valid_df['outcome']\n",
        "\n",
        "#create a model for Decision Trees, Random Forest and Logistic Regression\n",
        "#model for Decision Trees, declare and find the ideal depth for the tree\n",
        "for d in range(1, 11, 1):\n",
        "  tree_model = DecisionTreeClassifier(random_state=1234, max_depth=d)\n",
        "  tree_model.fit(features_train, target_train)  #train the model\n",
        "  #check for accuracy\n",
        "  print(f'Decision tree has accuracy of: {tree_model.score(features_train, target_train)} for depth of: {d}')\n",
        "\n",
        "#declare model for random forest and find the best n_estimator value\n",
        "for n in range(1,20,1):\n",
        "  forest_model = RandomForestClassifier(random_state=1234, n_estimators=n)\n",
        "  forest_model.fit(features_train, target_train)\n",
        "  print(f'Random forest has accuracy of: {forest_model.score(features_train, target_train)} for n={n}')\n",
        "\n",
        "#declare a model for logistic regression\n",
        "log_model = LogisticRegression(random_state=1234, solver='liblinear')\n",
        "log_model.fit(features_train, target_train)\n",
        "print(f'logistic regression has accuracy of: {log_model.score(features_train, target_train)}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VCD2qH545SgE",
        "outputId": "3c7b2a72-3bdd-48f6-88eb-792beb4b30c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision tree has accuracy of: 0.7353324641460235 for depth of: 1\n",
            "Decision tree has accuracy of: 0.771838331160365 for depth of: 2\n",
            "Decision tree has accuracy of: 0.7757496740547588 for depth of: 3\n",
            "Decision tree has accuracy of: 0.7913950456323338 for depth of: 4\n",
            "Decision tree has accuracy of: 0.8370273794002607 for depth of: 5\n",
            "Decision tree has accuracy of: 0.8513689700130378 for depth of: 6\n",
            "Decision tree has accuracy of: 0.8917861799217731 for depth of: 7\n",
            "Decision tree has accuracy of: 0.9282920469361148 for depth of: 8\n",
            "Decision tree has accuracy of: 0.9569752281616688 for depth of: 9\n",
            "Decision tree has accuracy of: 0.970013037809648 for depth of: 10\n",
            "Random forest has accuracy of: 0.8917861799217731 for n=1\n",
            "Random forest has accuracy of: 0.9074315514993481 for n=2\n",
            "Random forest has accuracy of: 0.9595827900912647 for n=3\n",
            "Random forest has accuracy of: 0.9556714471968709 for n=4\n",
            "Random forest has accuracy of: 0.9739243807040417 for n=5\n",
            "Random forest has accuracy of: 0.9687092568448501 for n=6\n",
            "Random forest has accuracy of: 0.9791395045632334 for n=7\n",
            "Random forest has accuracy of: 0.9817470664928292 for n=8\n",
            "Random forest has accuracy of: 0.984354628422425 for n=9\n",
            "Random forest has accuracy of: 0.9830508474576272 for n=10\n",
            "Random forest has accuracy of: 0.9882659713168188 for n=11\n",
            "Random forest has accuracy of: 0.9882659713168188 for n=12\n",
            "Random forest has accuracy of: 0.9921773142112125 for n=13\n",
            "Random forest has accuracy of: 0.9908735332464146 for n=14\n",
            "Random forest has accuracy of: 0.9973924380704041 for n=15\n",
            "Random forest has accuracy of: 0.9960886571056062 for n=16\n",
            "Random forest has accuracy of: 0.9960886571056062 for n=17\n",
            "Random forest has accuracy of: 0.9960886571056062 for n=18\n",
            "Random forest has accuracy of: 0.9973924380704041 for n=19\n",
            "logistic regression has accuracy of: 0.7757496740547588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0WqM7AtGDnuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Finding and Recommendation\n",
        "####Finding\n",
        "*   Out of the 3 models used Decision Trees, Random Forest and Logistic Regression only Decision Trees, Random Forest meets the criteria of more than 0.85 prediction accuracy.\n",
        "*    Decision Trees gives a prediction accuracy of >0.85 for tree depth of >=6\n",
        "*    Random Forest gives a prediction of >0.85 for n_estimator >=1\n",
        "\n",
        "####Recommendation\n",
        "Random Forest has the best accuracy but slow while Decision Tree has low accuracy but fast. the most optimal model would be Decision Trees tree depth of ==6 because it meets the criteria and fast\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jz-oMDgjDqnz"
      }
    }
  ]
}